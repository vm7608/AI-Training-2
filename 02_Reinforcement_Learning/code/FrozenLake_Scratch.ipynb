{
 "cells": [
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# **FROZEN LAKE**\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## **Set-up environment**\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "import numpy as np"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 156,
   "metadata": {},
   "outputs": [],
   "source": [
    "ENV_ROWs = 4\n",
    "ENV_COLs = 4\n",
    "ACTIONS = ['left', 'down', 'right', 'up']\n",
    "HOLES = [(1, 1), (1, 3), (2, 3), (3, 0)]\n",
    "START = (0, 0)\n",
    "GOAL = (3, 3)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 157,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[0. 0. 0. 0.]\n",
      "[0. 0. 0. 0.]\n",
      "[0. 0. 0. 0.]\n",
      "[0. 0. 0. 1.]\n"
     ]
    }
   ],
   "source": [
    "# Create rewards matrix\n",
    "REWARDS = np.full((ENV_ROWs, ENV_COLs), 0.)\n",
    "REWARDS[ENV_ROWs-1, ENV_COLs-1] = 1.\n",
    "for row in REWARDS:\n",
    "    print(row)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## **Create Q-table**\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 158,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "array([[0., 0., 0., 0.],\n",
       "       [0., 0., 0., 0.],\n",
       "       [0., 0., 0., 0.],\n",
       "       [0., 0., 0., 0.],\n",
       "       [0., 0., 0., 0.],\n",
       "       [0., 0., 0., 0.],\n",
       "       [0., 0., 0., 0.],\n",
       "       [0., 0., 0., 0.],\n",
       "       [0., 0., 0., 0.],\n",
       "       [0., 0., 0., 0.],\n",
       "       [0., 0., 0., 0.],\n",
       "       [0., 0., 0., 0.],\n",
       "       [0., 0., 0., 0.],\n",
       "       [0., 0., 0., 0.],\n",
       "       [0., 0., 0., 0.],\n",
       "       [0., 0., 0., 0.]])"
      ]
     },
     "execution_count": 158,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "# CREATE q-table\n",
    "Q_TABLE = np.full((ENV_ROWs*ENV_COLs, len(ACTIONS)), 0.0)\n",
    "Q_TABLE"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## **Define some helper functions**\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 159,
   "metadata": {},
   "outputs": [],
   "source": [
    "def is_terminal_state(current_row_index, current_column_index):\n",
    "    \"\"\"\n",
    "    Check if the current state is a terminal state.\n",
    "    Terminal states are the goal and the \"holes\" locations.\n",
    "    \"\"\"\n",
    "    position = (current_row_index, current_column_index)\n",
    "    if position == GOAL or position in HOLES:\n",
    "        return True\n",
    "    else:\n",
    "        return False\n",
    "\n",
    "\n",
    "def get_next_action(current_row_index, current_column_index, epsilon):\n",
    "    \"\"\"\n",
    "    Given the current state, select the next action to take based on the epsilon-greedy policy.\n",
    "    \"\"\"\n",
    "    # if a randomly chosen value between 0 and 1 is less than epsilon,\n",
    "    # then choose the most promising value from the Q-table for this state.\n",
    "    # else choose a random action.\n",
    "    if np.random.random() < epsilon:\n",
    "        return np.argmax(Q_TABLE[4*current_row_index+current_column_index, :])\n",
    "    else:\n",
    "        return np.random.randint(4)\n",
    "\n",
    "\n",
    "def get_next_location(current_row_index, current_column_index, action_index):\n",
    "    \"\"\"\n",
    "    Return the next location based on the action taken and the current location.\n",
    "    \"\"\"\n",
    "    new_row_index = current_row_index\n",
    "    new_column_index = current_column_index\n",
    "    if ACTIONS[action_index] == 'up' and current_row_index > 0:\n",
    "        new_row_index -= 1\n",
    "    elif ACTIONS[action_index] == 'right' and current_column_index < ENV_COLs - 1:\n",
    "        new_column_index += 1\n",
    "    elif ACTIONS[action_index] == 'down' and current_row_index < ENV_ROWs - 1:\n",
    "        new_row_index += 1\n",
    "    elif ACTIONS[action_index] == 'left' and current_column_index > 0:\n",
    "        new_column_index -= 1\n",
    "    return new_row_index, new_column_index\n",
    "\n",
    "\n",
    "def get_path_to_goal(start_row_index, start_column_index):\n",
    "    \"\"\"\n",
    "    Return the path to the goal using the greedy approach.\n",
    "    \"\"\"\n",
    "    # return immediately if this is an invalid starting location\n",
    "    if is_terminal_state(start_row_index, start_column_index):\n",
    "        return []\n",
    "    else:\n",
    "        current_row_index, current_column_index = start_row_index, start_column_index\n",
    "        path_to_goal = []\n",
    "        path_to_goal.append([current_row_index, current_column_index])\n",
    "        # continue moving along the path until we reach the goal (i.e., the item packaging location)\n",
    "        while not is_terminal_state(current_row_index, current_column_index):\n",
    "            # get the best action to take\n",
    "            best_action_index = np.argmax(\n",
    "                Q_TABLE[4*current_row_index+current_column_index, :])\n",
    "            # move to the next location on the path, and add the new location to the list\n",
    "            current_row_index, current_column_index = get_next_location(\n",
    "                current_row_index, current_column_index, best_action_index)\n",
    "            path_to_goal.append([current_row_index, current_column_index])\n",
    "        return path_to_goal"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## **Train agent**\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### **Define hyperparameters**\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 161,
   "metadata": {},
   "outputs": [],
   "source": [
    "total_episodes = 10000\n",
    "max_steps = 99\n",
    "\n",
    "learning_rate = 0.7\n",
    "\n",
    "# discounting rate\n",
    "gamma = 0.95\n",
    "\n",
    "# exploration rate\n",
    "max_epsilon = 1.0\n",
    "min_epsilon = 0.05\n",
    "decay_rate = 0.0005"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### **Train using Q-learning algorithm**\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 162,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Training complete!\n"
     ]
    }
   ],
   "source": [
    "for episode in range(total_episodes):\n",
    "\n",
    "    # change epsilon for this episode\n",
    "    epsilon = min_epsilon + (max_epsilon - min_epsilon) * \\\n",
    "        np.exp(-decay_rate*episode)\n",
    "\n",
    "    # get the starting location for this episode\n",
    "    row_index, column_index = START\n",
    "\n",
    "    for step in range(max_steps):\n",
    "        action_index = get_next_action(row_index, column_index, epsilon)\n",
    "\n",
    "        old_row_index, old_column_index = row_index, column_index\n",
    "        row_index, column_index = get_next_location(\n",
    "            row_index, column_index, action_index)\n",
    "\n",
    "        reward = REWARDS[row_index, column_index]\n",
    "        old_q_value = Q_TABLE[4*old_row_index + old_column_index, action_index]\n",
    "        temporal_difference = reward + \\\n",
    "            (gamma * np.max(Q_TABLE[4*row_index +\n",
    "             column_index, :])) - old_q_value\n",
    "\n",
    "        # update the Q-value for the previous state and action pair\n",
    "        new_q_value = old_q_value + (learning_rate * temporal_difference)\n",
    "        Q_TABLE[4*old_row_index + old_column_index, action_index] = new_q_value\n",
    "\n",
    "        done = is_terminal_state(row_index, column_index)\n",
    "        if done == True:\n",
    "            break\n",
    "\n",
    "print('Training complete!')"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## **View Q-table results**\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 163,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>left</th>\n",
       "      <th>down</th>\n",
       "      <th>right</th>\n",
       "      <th>up</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>0.735</td>\n",
       "      <td>0.774</td>\n",
       "      <td>0.774</td>\n",
       "      <td>0.735</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1</th>\n",
       "      <td>0.735</td>\n",
       "      <td>0.000</td>\n",
       "      <td>0.815</td>\n",
       "      <td>0.774</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2</th>\n",
       "      <td>0.774</td>\n",
       "      <td>0.857</td>\n",
       "      <td>0.774</td>\n",
       "      <td>0.815</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>3</th>\n",
       "      <td>0.815</td>\n",
       "      <td>0.000</td>\n",
       "      <td>0.774</td>\n",
       "      <td>0.774</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>4</th>\n",
       "      <td>0.774</td>\n",
       "      <td>0.815</td>\n",
       "      <td>0.000</td>\n",
       "      <td>0.735</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>5</th>\n",
       "      <td>0.000</td>\n",
       "      <td>0.000</td>\n",
       "      <td>0.000</td>\n",
       "      <td>0.000</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>6</th>\n",
       "      <td>0.000</td>\n",
       "      <td>0.902</td>\n",
       "      <td>0.000</td>\n",
       "      <td>0.815</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>7</th>\n",
       "      <td>0.000</td>\n",
       "      <td>0.000</td>\n",
       "      <td>0.000</td>\n",
       "      <td>0.000</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>8</th>\n",
       "      <td>0.815</td>\n",
       "      <td>0.000</td>\n",
       "      <td>0.857</td>\n",
       "      <td>0.774</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>9</th>\n",
       "      <td>0.815</td>\n",
       "      <td>0.902</td>\n",
       "      <td>0.902</td>\n",
       "      <td>0.000</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>10</th>\n",
       "      <td>0.857</td>\n",
       "      <td>0.950</td>\n",
       "      <td>0.000</td>\n",
       "      <td>0.857</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>11</th>\n",
       "      <td>0.000</td>\n",
       "      <td>0.000</td>\n",
       "      <td>0.000</td>\n",
       "      <td>0.000</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>12</th>\n",
       "      <td>0.000</td>\n",
       "      <td>0.000</td>\n",
       "      <td>0.000</td>\n",
       "      <td>0.000</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>13</th>\n",
       "      <td>0.000</td>\n",
       "      <td>0.902</td>\n",
       "      <td>0.950</td>\n",
       "      <td>0.857</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>14</th>\n",
       "      <td>0.902</td>\n",
       "      <td>0.950</td>\n",
       "      <td>1.000</td>\n",
       "      <td>0.902</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>15</th>\n",
       "      <td>0.000</td>\n",
       "      <td>0.000</td>\n",
       "      <td>0.000</td>\n",
       "      <td>0.000</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "</div>"
      ],
      "text/plain": [
       "     left   down  right     up\n",
       "0   0.735  0.774  0.774  0.735\n",
       "1   0.735  0.000  0.815  0.774\n",
       "2   0.774  0.857  0.774  0.815\n",
       "3   0.815  0.000  0.774  0.774\n",
       "4   0.774  0.815  0.000  0.735\n",
       "5   0.000  0.000  0.000  0.000\n",
       "6   0.000  0.902  0.000  0.815\n",
       "7   0.000  0.000  0.000  0.000\n",
       "8   0.815  0.000  0.857  0.774\n",
       "9   0.815  0.902  0.902  0.000\n",
       "10  0.857  0.950  0.000  0.857\n",
       "11  0.000  0.000  0.000  0.000\n",
       "12  0.000  0.000  0.000  0.000\n",
       "13  0.000  0.902  0.950  0.857\n",
       "14  0.902  0.950  1.000  0.902\n",
       "15  0.000  0.000  0.000  0.000"
      ]
     },
     "execution_count": 163,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "import pandas as pd\n",
    "q_df = pd.DataFrame(np.round(Q_TABLE, 3), columns=ACTIONS)\n",
    "q_df"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 164,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Shortest path from start to goal:\n",
      "[[0, 0], [1, 0], [2, 0], [2, 1], [3, 1], [3, 2], [3, 3]]\n"
     ]
    }
   ],
   "source": [
    "print('Shortest path from start to goal:')\n",
    "print(get_path_to_goal(0, 0))"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": ".venv",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.11.5"
  },
  "orig_nbformat": 4
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
